from typing import Dict
import logging

from overrides import overrides

import tqdm
import numpy as np

from allennlp.common import Params
from allennlp.common.file_utils import cached_path
from allennlp.data.dataset_readers.dataset_reader import DatasetReader
from allennlp.data.fields import ArrayField
from allennlp.data.instance import Instance

logger = logging.getLogger(__name__)  # pylint: disable=invalid-name


@DatasetReader.register("wordpair_bigram_vectors")
class BigramEmbedderDatasetReader(DatasetReader):
    """
    Reads a .tsv file generated by the last `step5...` data generation script.
    The data is stored into `step5...` sub-folder of the `data` folder.

    Data file contains vectors for bigram and the words it consists of.
    This dataset reader creates dataset suitable for predicting future bigram vectors from it's word vectors.

    Expected format for each input line: `bigram_type    bigram_vector   word1_vector    word2_vector`

    The output of ``read`` is a list of ``Instance`` s with the fields:
        word1_vector: ``ArrayField``
        word2_vector: ``ArrayField``
        bigram_vector: ``ArrayField`` (optional)

    Parameters
    ----------
    lazy : ``bool`` (optional, default=False)
        Passed to ``DatasetReader``.  If this is ``True``, training will start sooner, but will
        take longer per batch.  This also allows training with datasets that are too large to fit
        in memory.
    """
    def __init__(self, lazy: bool = False) -> None:
        super().__init__(lazy)

    @overrides
    def _read(self, file_path):
        with open(cached_path(file_path), "r") as data_file:
            logger.info("Reading vectors from lines in file at: %s", file_path)
            for line_num, line in enumerate(tqdm.tqdm(data_file.readlines())):
                line = line.strip("\n")
                if not line:
                    continue

                _, bigram_vector_str, word1_vector_str, word2_vector_str = line.split('\t')
                yield self.text_to_instance(word1_vector_str, word2_vector_str, bigram_vector_str)

    @overrides
    def text_to_instance(self, word1_vector_str: str, word2_vector_str: str, bigram_vector_str: str = None) -> Instance:  # type: ignore
        # pylint: disable=arguments-differ
        word1_vector = np.array([float(v) for v in word1_vector_str.split()])
        word2_vector = np.array([float(v) for v in word2_vector_str.split()])

        word1_vector_filed = ArrayField(word1_vector)
        word2_vector_filed = ArrayField(word2_vector)

        fields = {'word1_vector': word1_vector_filed, 'word2_vector': word2_vector_filed}

        if bigram_vector_str:
            bigram_vector = np.array([float(v) for v in bigram_vector_str.split()])
            bigram_vector_field = ArrayField(bigram_vector)
            fields['bigram_vector'] = bigram_vector_field

        return Instance(fields)

    @classmethod
    def from_params(cls, params: Params) -> 'BigramEmbedderDatasetReader':
        lazy = params.pop('lazy', False)
        params.assert_empty(cls.__name__)
        return cls(lazy=lazy)
